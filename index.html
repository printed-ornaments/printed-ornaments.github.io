<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Historical Printed Ornaments: Dataset and Tasks</title>
  <link rel="stylesheet" href="styles.css">
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      text-align: center;
      padding: 50px;
    }

    h1,
    h2 {
      color: #333;
    }

    p {
      color: #666;
      line-height: 1.6;
    }

    .aligncenter {
      text-align: center;
    }

    .button-container {
      vertical-align: center;
      margin-bottom: 20px;
    }

    /* CSS for each button */
    .image-button {
      display: inline-block;
      border: none;
      padding: 0;
      margin: 0 10px;
      /* Add some space between buttons */
      background: none;
      cursor: pointer;
      border-radius: 10px;
      /* Rounded corners */
      overflow: hidden;
      /* Ensure rounded corners are visible */
      position: relative;
      /* Positioning for the text */
      transition: background-color 0.3s;
      /* Smooth transition for hover effect */
    }

    /* CSS for the image in each button */
    .image-button img {
      width: 250px;
      /* Adjust the width of the image */
      height: 350;
      display: block;
    }

    /* Darken the button on hover */
    .image-button:hover {
      background-color: rgba(0, 0, 0, 0.2);
      /* Darken the background color */
    }

    /* CSS for the text in each button */
    .image-button-text {
      position: absolute;
      bottom: 10px;
      /* Adjust the vertical position of the text */
      left: 50%;
      transform: translateX(-50%);
      color: transparent;
      /* Initially transparent */
      font-size: 16px;
      font-family: 'Genova', sans-serif;
      /* Use Genova font */
      opacity: 0;
      /* Initially hidden */
      transition: opacity 0.3s, color 0.3s;
      /* Smooth transition for visibility and color */
    }

    /* Show the text when hovering */
    .image-button:hover .image-button-text {
      opacity: 1;
      /* Show the text */
      color: black;
      /* Change the text color to black */
      background-color: white;
    }

    .cool-button {
      padding: 10px 20px;
      background-color: #e74c3c;
      text-decoration: none;
      /* Remove underline */
      color: #ffffff;
      border: none;
      border-radius: 5px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    .cool-button:hover {
      background-color: transparent;
      border: 2px solid #e74c3c;
      color: #e74c3c;
    }

    .button-blue {
      padding: 10px 20px;
      background-color: #007bff;
      text-decoration: none;
      color: #ffffff;
      border: none;
      border-radius: 5px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s ease;
    }

    .button-blue:hover {
      background-color: transparent;
      border: 2px solid #007bff;
      color: #007bff;
    }

    .authors {
      margin: auto;
      max-width: 800px;
      margin-bottom: 30px;
      margin-top: 30px;
    }

    .authors a {
      margin: 10px;
      text-decoration: none;
      color: #007bff;
      font-size: 16px;
      transition: color 0.3s ease;
    }

    .authors a:hover {
      color: #0056b3;
    }

    .tasks-container {
      text-align: justify;
      max-width: 800px;
      margin: auto;
      margin-top: 50px;
    }

    .tasks {
      margin-top: 20px;
    }

    .tasks h2 {
      color: #333;
      font-size: 24px;
      text-align: center;
      margin-bottom: 20px;
    }

    .bibtex-container {
      max-width: 800px;
      margin: auto;
      margin-top: 50px;
    }

    .bibtex {
      margin-top: 20px;
      background-color: #fff;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);
    }

    .bibtex h2 {
      text-align: center;
      color: #000;
      font-size: 24px;
      margin-bottom: 20px;
    }

    .bibtex p {
      overflow-wrap: break-word;
      color: white;
      background-color: #444;
      font-size: 14px;
      padding: 10px;
      border-radius: 5px;
    }


    .line {
      border-bottom: 2px solid #ddd;
      margin: 20px 0;
    }

    .teaser img {
      max-width: 800px;
      display: inline-block;
      overflow: auto;
      margin-left: auto;
      margin-right: auto;
      margin-top: 50px;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);
    }

    /* Styles for Results Section */
    .results {
      text-align: justify;
      max-width: 800px;
      margin: auto;
      margin-top: 50px;
      background-color: #fff;
      border-radius: 10px;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.1);
    }

    .results h2 {
      color: #333;
      font-size: 24px;
      margin-bottom: 20px;
      text-align: center;
    }

    .result-item {
      margin-top: 20px;
      margin-right: auto;
      margin-left: auto;
    }

    .result-item h3 {
      color: #333;
      font-size: 20px;
      margin-bottom: 10px;
      text-align: center;
    }

    .headings {
      max-width: 1400px;
      margin: auto;
    }
  </style>
</head>
<div class="headings">
  <img src="./images/Untitled drawing(4).png" width=100% height=100%>
</div>
<h1>Historical Printed Ornaments: Dataset and Tasks</h1>
<p>ICDAR 2024</p>

<div class="authors">
  <a href="https://www.linkedin.com/in/sayan-chaki-lhc" target="_blank">Sayan K Chaki</a>
  <a href="https://imagine-lab.enpc.fr/staff-members/sonat-baltaci/" target="_blank">Sonat Baltaci</a>
  <a href="https://imagine.enpc.fr/~vincente/" target="_blank">Elliot Vincent</a>

  <a href="https://home.heeere.com/" target="_blank">Rémi Emonet</a>
  <a href="http://ihrim.ens-lyon.fr/auteur/vial-bonacci-fabienne" target="_blank">Fabienne Vial-Bonacci</a>
  <a href="http://ihrim.ens-lyon.fr/auteur/bahier-porte-christelle" target="_blank">Christelle Bahier-Porte</a>
  <a href="https://imagine.enpc.fr/~aubrym/" target="_blank">Mathieu Aubry</a>
  <a href="https://orcid.org/0000-0002-1613-4594" target="_blank">Thierry Fournel</a>
</div>
<a href="https://github.com/printed-ornaments/reys-dataset" class="button-blue">Dataset & Code</a>
<a href="https://ro2i.hypotheses.org/" class="cool-button">ROIi Project</a>
<a href="link_to_arxiv" class="button-blue">ArXiv</a>
<a onclick="scrollToSection('bibtex-section')" class="cool-button">Bibtex</a>
<script>
  function scrollToSection(sectionId) {
    var section = document.getElementById(sectionId);
    if (section) {
      section.scrollIntoView({ behavior: 'smooth' });
    }
  }
</script>
<div class="teaser">
  <img src="./images/teaser.png" width=100% height=100%>
</div>
<div class="results">
  <h2>Abstract</h2>
  <p>This paper aims to develop the study of historical printed ornaments with modern unsupervised computer vision. We
    highlight three complex tasks that are of critical interest to book historians: clustering, element discovery, and
    unsupervised change localization. For each of these tasks, we introduce an evaluation benchmark, and we adapt and
    evaluate state-of-the-art models. Our <i>Rey's Ornaments dataset</i> is designed to be a representative example of a
    set of ornaments historians would be interested in. It focuses on an XVIIIth century bookseller, Marc-Michel Rey,
    providing a consistent set of ornaments with a wide diversity and representative challenges. Our results highlight
    the limitations of state-of-the-art models when faced with real data and show simple baselines such as k-means or
    congealing can outperform more sophisticated approaches.</p>
</div>

<div class="tasks-container">
  <div class="tasks">
    <h2>Dataset and Tasks</h2>
    <div class="line"></div> <!-- Line Separator -->
    <p>Our Rey's Ornaments dataset is composed of three parts, giving insights into our three tasks:</p>
    <ul>
      <li>
        <p>The <b>clustering dataset</b>, based on woodblock ornaments, includes 167 images of 36 different ornaments,
          each associated with 3 to 14 occurrences. We found that DTI Clustering [1] outperformed state-of-the-art
          clustering approaches by a large margin on a balanced subset of images, but that the k-means algorithm [2] on
          the foundation features (e.g., CLIP [3]) was on-par with DTI Clustering on the full imbalanced dataset.
          However, all algorithms led to less than 80% accuracy in this setting.</p>
      </li>
      <li>
        <p>The <b>element discovery dataset</b> includes 100 images of composite ornaments containing 1271 elements,
          from a dictionary of 72 different vignettes. We found all unsupervised element discovery methods to perform
          poorly. We believe this stresses the potential benefit of our dataset for the community, compared to the
          synthetic datasets often used to evaluate unsupervised object segmentation methods.</p>
      </li>
      <li>
        <p>The <b>unsupervised change localization dataset</b> includes 30 types of vignettes with four reference
          instances and two test instances, a normal one and one where changes have been annotated. We found that direct
          reconstruction-based approaches, such as congealing [4] or VAE-based [5], performed poorly compared to human
          annotations, mostly because they are confused by the variations in inking. We see this as an invitation to
          better formalize the notion of changes relevant to book historians and design-associated algorithms.</p>
      </li>
    </ul>

  </div>
</div>

<!-- Results Section -->
<div class="results">
  <h2>Qualitative Results</h2>
  <div class="result-item">
    <h3>Block Ornaments and Clustering</h3>
    <p class="aligncenter">
      <img src="./images/clustering_qual.png" width=100% height=100%>
    </p>
  </div>
  <div class="result-item">
    <h3>Composite Ornaments and Element Discovery</h3>
    <p class="aligncenter">
      <img src="./images/discovery_qual.png" width=100% height=100%>
    </p>
  </div>
  <div class="result-item">
    <h3>Vignettes and Unsupervised Change Localization</h3>
    <p class="aligncenter">
      <img src="./images/change_qual.png" width=100% height=100%>
    </p>
  </div>
</div>
<!-- Heading -->
<div class="tasks-container">
  <div class="tasks">
    <h2>Project Links</h2>
    <div class="line"></div> <!-- Line Separator -->
    <!-- Button Container -->
    <div class="button-container">
      <!-- HTML for the image button 1 -->
      <a href="arxiv-link" class="image-button">
        <img src="./images/paper.png" alt="Button Image 1" width="200px" height="275px">
        <span class="image-button-text">Paper</span>
      </a>

      <!-- HTML for the image button 2 -->
      <a href="https://github.com/printed-ornaments/reys-dataset" class="image-button">
        <img src="./images/reys-dataset.png" alt="Button Image 2" width="200px" height="275px">
        <span class="image-button-text">Code</span>
      </a>

      <!-- HTML for the image button 3 -->
      <a href="https://drive.google.com/drive/folders/1FBOrEBukX8j_K9wO8LiRlCJAnH_ivZW6?usp=sharing"
        class="image-button">
        <img src="./images/data.jpg" alt="Button Image 3" width="200px" height="275px">
        <span class="image-button-text">Dataset</span>
      </a>
    </div>
  </div>
</div>
<div id="bibtex-section" class="bibtex-container">
  <div class="bibtex">
    <h2>Bibtex</h2>
    <p>@inproceedings{chaki2024historical, <br>
      title={Historical Printed Ornaments: Dataset and Tasks}, <br>
      author={Chaki, Sayan and Baltaci, Sonat and Vincent, Elliot
      and Emonet, Rémi and Vial-Bonacci, Fabienne and Bahier-Porte, Christelle
      and Aubry, Mathieu and Fournel, Thierry},<br>
      booktitle={ICDAR}, <br>
      year={2024}}</p>
  </div>
</div>
<div class="tasks-container">
  <div class="tasks">
    <h2>Acknowledgement</h2>
    <div class="line"></div> <!-- Line Separator -->
    <p>This work was funded by ANR ROIi project ANR-20-CE38-0005. S. Baltaci, E. Vincent, and M. Aubry were supported by
      ERC project DISCOVER funded by the European Union’s Horizon Europe Research and Innovation program under grant
      agreement No. 101076028 and ANR VHS project ANR-21-CE38-0008. We thank Silya Ounoughi, Thomas Gautrais, and
      Vincent
      Ventresque for their work in the collection and annotation of the datasets, and Ségolène Albouy, Raphaël Baena,
      Syrine Kalleli, Ioannis Siglidis, Gurjeet Singh, Andrea Morales and Malamatenia Vlachou for valuable feedbacks.
    </p>
    <h2>References</h2>
    <div class="line"></div> <!-- Line Separator -->
    <p>[1] Monnier, T., Groueix, T., Aubry, M.: Deep Transformation-Invariant Clustering. In: NeurIPS (Oct 2020) <br>
      [2] MacQueen, J., et al.: Some methods for classification and analysis of multivariate
      observations. In: Proceedings of the fifth Berkeley symposium on mathematical
      statistics and probability. vol. 1, pp. 281–297. Oakland, CA, USA (1967) <br>
      [3] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G.,
      Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable visual models from
      natural language supervision. In: International conference on machine learning. pp.
      8748–8763. PMLR (2021)<br>
      [4] Cox, M., Sridharan, S., Lucey, S., Cohn, J.: Least squares congealing for unsu-
      pervised alignment of images. In: 2008 IEEE Conference on Computer Vision and
      Pattern Recognition. pp. 1–8 (2008). <br>
      [5] Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: 2nd International
      Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April
      14-16, 2014, Conference Track Proceedings (2014) <br>
    </p>
  </div>
</div>

</body>

</html>